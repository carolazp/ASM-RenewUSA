---
title: 'ASM TS Project: RenewUSA'
author: "Kathryn Weissman & Carol Azparrent"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
rm(list=ls())
#setwd("~/Documents/ASM/Project")
```

Total production of renewable energy in USA (trillions of BTU-British Thermal Units)

https://www.eia.gov/totalenergy/data/browser/index.php?tbl=T10.01#/?f=M&start=199001&end=201901&charted=6-7-8-9-14

According to the source data website, this time series is an aggregation of different renewable energy sources including: hydroelectric power, geothermal, solar, wind, and biomass.

Biomass, wind, and solar energy have become more popular starting at different times after 2005 which explains some of the variation in the series.


```{r renewUSA}
series = window(ts(read.table("data/RenewUSA.dat", header=F),start=1990,freq=12))
series
```

```{r plotSeries}
plot(series,main="Total production of renewable energy (USA)", ylab='Trillion Btu', ylim=c(0,1200))
abline(v=1990:2020,col=4,lty=3)
```
1. Identification
1.a) Transform into stationary Time Series

## is the variance constant?

```{r}
floor(time(series))
```


```{r}
boxplot(series~floor(time(series)), ylab="Trillion Btu", xlab="Year", main="Boxplots grouped by Year") 
```
```{r}
#boxplot for periods of 12 observations = 1 year
groupedserie <- matrix(series[1:(30*12)], ncol = 30) #boxplot of each year
boxplot(groupedserie)
```
```{r}
# groupedserie : serie with periods (periods of 12 months = 1 year)
m<-apply(groupedserie,2,mean)
v<-apply(groupedserie,2,var)
plot(v~m)
abline(lm(v~m),col=2,lty=3) #col: color of line, lty:type of line
# for mean vs variance (v = s^2) -> there is an increasing
# ===> THE VARIANCE IS NOT CONSTANT --> we have to take logarithmic
```
```{r}
groupedserie
```

Variance not constant: change the scale = logarithms
```{r}
# now, we apply the logarithmic to "series"
lnserie=log(series)
plot(lnserie)
abline(v=1990:2020,col=4,lty=3)
abline(h=0)
```


## is there a seasonal pattern?

```{r}
monthplot(lnserie)
#there is a seasonal pattern
```
```{r}
ts.plot(matrix(lnserie,nrow=12),col=1:8)
#most of them are in parallel -> so there is a seasonal pattern
```
so, we take seasonal difference
```{r}
d12lnserie <- diff(lnserie, lag=12)
plot(d12lnserie)
#12 because it's 12 months data in a year
```
```{r}
monthplot(d12lnserie) #no more seasonal pattern
```
```{r}
ts.plot(matrix(d12lnserie,nrow=12),col=1:8)
#no more seasonal pattern (not in parallel)
```
now we work with "d12lnserie"


## is the mean constant?
```{r}
plot(d12lnserie, ylab='d12lnserie', main='Renewable Energy Production (log, s=12)')
abline(h=0)
abline(h=mean(d12lnserie),col=2)
#constant mean = yes
# this mean in 0? no
```
```{r}
mean(d12lnserie)
```
add regular difference:
```{r}
d1d12lnserie = diff(d12lnserie)
plot(d1d12lnserie, ylab='d1d12lnserie', main='Renewable Energy Production (log, s=12, d=1)')
abline(h=0)
abline(h=mean(d1d12lnserie), col=2)
```
```{r}
mean(d1d12lnserie) 
#mean different from 0  --> differentation
```

Comparing the variance to choose the best one:
```{r}
var(d12lnserie) #d=0
var(d1d12lnserie) #d=1 **************
var(diff(d1d12lnserie)) #d=2

```
d=1 wins as it has the lower variance. 
We would take only one differentation.
W_t = (1-B)(1-B^12)X_t , d=1

we applied first log X_t then, seasonal difference (s=12) as we had seasonal pattern, and finally we added one regular difference.

So now, we work with "d1d12lnserie"
we have:
- seasonal difference
- one regular difference


1.b) ################# ACF/PACF regular & seasonal #####################################
NEXT PART: Analysis ACF/PACF  W_t ==>> p,q, P,Q

seasonal part: (P,D,Q)_12
regular part: p,d,q
ARMA(p,d,q)(P,D,Q)_12
```{r}
# now we work only with d1d12lnserie
par(mfrow=c(1,2))
acf(d1d12lnserie, ylim=c(-1,1), lag.max = 72,col=c(2,rep(1,11)),lwd=2)
pacf(d1d12lnserie, ylim=c(-1,1), lag.max = 72,col=c(rep(1,11),2),lwd=2)
par(mfrow=c(1,1))

#SEASONAL: red lines
#REGULAR: black lines
```
# SEASONAL: red lines
  MA(1)_12
  MA(2)_12 - possibly

# REGULAR: black lines
  MA(2)

  
reminder: we work with "d1d12lnserie"
d = 1
D = 1

To calculate ARIMA, we need "LNSERIE". NOT the difference (neither seasonal, nor regular)

ARIMA(p,d,q)(P,D,Q)_S

note: AR(Pp), MA(Qq)

ARIMA(0,1,2)(0,1,1)_12
ARIMA(0,1,2)(0,1,2)_12

#########################################
FIRST POSIBLE MODEL:  regular part: MA(q=2) | seasonal part:MA(Q=1)_12
```{r}
# ARIMA(0,1,2)(0,1,1)_12
(mod1 <- arima(lnserie, order=c(0,1,2), seasonal=list(order=c(0,1,1),period = 12)))
                  #REGULAR PART:MA(2)     #SEASONAL PART:MA(1)_12     #PERIOD FOR THE SEASONAL PART       
```
all the coefficient are significant.

```{r}
# checking the residuals: Z_t
# we need all the flags lying inside the band: Z_t ~ WN(0, (SIGMA_z)^2 )
par(mfrow=c(1,2))
acf(resid(mod1), ylim=c(-1,1), lag.max = 72,col=c(2,rep(1,11)),lwd=2)
pacf(resid(mod1), ylim=c(-1,1), lag.max = 72,col=c(rep(1,11),2),lwd=2)
par(mfrow=c(1,1))
```
almost all lags are inside the band. ok


```{r}
par(mfrow=c(1,1))
tsdiag(mod1,gof=72)
```


#########################################
SECOND POSIBLE MODEL:  regular part: MA(q=2) | seasonal part:  MA(2)_12

```{r}
# ARIMA(0,1,2)(0,1,2)_12
(mod2 <- arima(lnserie, order=c(0,1,2), seasonal=list(order=c(0,1,2),period = 12)))
                  #REGULAR PART:MA(2)     #SEASONAL PART:MA(2)_12     #PERIOD FOR THE SEASONAL PART       
```
all the coefficient are significant.


```{r}
# checking the residuals: Z_t
# we need all the flags lying inside the band: Z_t ~ WN(0, (SIGMA_z)^2 )
par(mfrow=c(1,2))
acf(resid(mod2), ylim=c(-1,1), lag.max = 72,col=c(2,rep(1,11)),lwd=2)
pacf(resid(mod2), ylim=c(-1,1), lag.max = 72,col=c(rep(1,11),2),lwd=2)
par(mfrow=c(1,1))
```
almost all lags are inside the band. ok

```{r}
par(mfrow=c(1,1))
tsdiag(mod2,gof=72)
```


The AIC:
mod1: ARIMA(0,1,2)(0,1,1)_12   ==> -1230.79
mod2: ARIMA(0,1,2)(0,1,2)_12   ==> -1235.66


EXTRA MODELS:
mod3: ARIMA(0,1,2)(4,1,0)_12   ==> -1213.08
mod4: ARIMA(0,1,2)(1,1,1)_12   ==> -1235.35
mod5: ARIMA(1,1,1)(1,1,1)_12   ==> -1231.47
mod6: ARIMA(1,1,1)(0,1,1)_12   ==> -1226.75
these are the extra models that may we consider. 

However, it won't be necessary as the lowest AIC has the mod2 model with a -1235.66 of AIC.

```{r}
# ARIMA(0,1,2)(4,1,0)_12
(mod3 <- arima(lnserie, order=c(0,1,2), seasonal=list(order=c(4,1,0),period = 12)))

# ARIMA(0,1,2)(1,1,1)_12
(mod4 <- arima(lnserie, order=c(0,1,2), seasonal=list(order=c(1,1,1),period = 12)))

# ARIMA(1,1,1)(1,1,1)_12
(mod5 <- arima(lnserie, order=c(1,1,1), seasonal=list(order=c(1,1,1),period = 12)))

# ARIMA(1,1,1)(0,1,1)_12
(mod6 <- arima(lnserie, order=c(1,1,1), seasonal=list(order=c(0,1,1),period = 12)))
```
We can the residuals of each model changing the number of the model in "mod#"
```{r}
# checking the residuals: Z_t
# we need all the flags lying inside the band: Z_t ~ WN(0, (SIGMA_z)^2 )
par(mfrow=c(1,2))
acf(resid(mod3), ylim=c(-1,1), lag.max = 72,col=c(2,rep(1,11)),lwd=2)
pacf(resid(mod3), ylim=c(-1,1), lag.max = 72,col=c(rep(1,11),2),lwd=2)
par(mfrow=c(1,1))
```
almost all lags are inside the band. ok

```{r}
par(mfrow=c(1,1))
tsdiag(mod3,gof=72)
```

```{r}
      
```



```{r}
#################Validation#################################
validation=function(model){
  s=frequency(get(model$series))
  resid=model$residuals
  par(mfrow=c(2,2),mar=c(3,3,3,3))
  #Residuals plot
  plot(resid,main="Residuals")
  abline(h=0)
  abline(h=c(-3*sd(resid),3*sd(resid)),lty=3,col=4)
  #Square Root of absolute values of residuals (Homocedasticity)
  scatter.smooth(sqrt(abs(resid)),main="Square Root of Absolute residuals",
                 lpars=list(col=2))
  
  #Normal plot of residuals
  qqnorm(resid)
  qqline(resid,col=2,lwd=2)
  
  ##Histogram of residuals with normal curve
  hist(resid,breaks=20,freq=FALSE)
  curve(dnorm(x,mean=mean(resid),sd=sd(resid)),col=2,add=T)
  
  
  #ACF & PACF of residuals
  par(mfrow=c(1,2))
  acf(resid,ylim=c(-1,1),lag.max=60,col=c(2,rep(1,s-1)),lwd=1, main='ACF residuals')
  pacf(resid,ylim=c(-1,1),lag.max=60,col=c(rep(1,s-1),2),lwd=1, main='PACF residuals')
  par(mfrow=c(1,1))
  
  #Ljung-Box p-values
  par(mar=c(2,2,1,1))
  tsdiag(model,gof.lag=7*s)
  cat("\n--------------------------------------------------------------------\n")
  print(model)
  
  #Stationary and Invertible
  cat("\nModul of AR Characteristic polynomial Roots: ", 
      Mod(polyroot(c(1,-model$model$phi))),"\n")
  cat("\nModul of MA Characteristic polynomial Roots: ",
      Mod(polyroot(c(1,model$model$theta))),"\n")
  
  suppressMessages(require(forecast,quietly=TRUE,warn.conflicts=FALSE))
  plot(model)
  
  #Model expressed as an MA infinity (psi-weights)
  psis=ARMAtoMA(ar=model$model$phi,ma=model$model$theta,lag.max=36)
  names(psis)=paste("psi",1:36)
  cat("\nPsi-weights (MA(inf))\n")
  cat("\n--------------------\n")
  print(psis[1:24])
  
  #Model expressed as an AR infinity (pi-weights)
  pis=-ARMAtoMA(ar=-model$model$theta,ma=-model$model$phi,lag.max=36)
  names(pis)=paste("pi",1:36)
  cat("\nPi-weights (AR(inf))\n")
  cat("\n--------------------\n")
  print(pis[1:24])
   
  cat("\nDescriptive Statistics for the Residuals\n")
  cat("\n----------------------------------------\n") 
  
  suppressMessages(require(fBasics,quietly=TRUE,warn.conflicts=FALSE))
  ##Anderson-Darling test
  print(basicStats(resid))
  
  ## Add here complementary tests (use with caution!)
  ##---------------------------------------------------------
  cat("\nNormality Tests\n")
  cat("\n--------------------\n")
 
  ##Shapiro-Wilks Normality test
  print(shapiro.test(resid))

  suppressMessages(require(nortest,quietly=TRUE,warn.conflicts=FALSE))
  ##Anderson-Darling test
  print(ad.test(resid))
  
  suppressMessages(require(tseries,quietly=TRUE,warn.conflicts=FALSE))
  ##Jarque-Bera test
  print(jarque.bera.test(resid))
  
  cat("\nHomoscedasticity Test\n")
  cat("\n--------------------\n")
  suppressMessages(require(lmtest,quietly=TRUE,warn.conflicts=FALSE))
  ##Breusch-Pagan test
  obs=get(model$series)
  print(bptest(resid~I(obs-resid)))
  
  cat("\nIndependence Tests\n")
  cat("\n--------------------\n")
  
  ##Durbin-Watson test
  print(dwtest(resid~I(1:length(resid))))
  
  ##Ljung-Box test
  cat("\nLjung-Box test\n")
  print(t(apply(matrix(c(1:4,(1:4)*s)),1,function(el) {
    te=Box.test(resid,type="Ljung-Box",lag=el)
    c(lag=(te$parameter),statistic=te$statistic[[1]],p.value=te$p.value)})))
  
}
################# Fi Validation #################################
```

```{r}
validation(mod1)
```
```{r}
validation(mod2)
```

We want to check for stability here.

The magnitude, sign, and significance of the coefficients for both models A and B are similar.

model B is based on the training data set.
model A is based on the whole data set.

Model 2 is Stable.

```{r}
# Based on Model 2
ultim=c(2018,12) # ending one year before the end of the time series: 12 observations

# Model 2 Parameters
pdq=c(0,1,2)
PDQ=c(0,1,2)

serie2=window(series,end=ultim)
lnserie2=log(serie2)
serie1=window(series,end=ultim+c(1,0)) # adds one year
lnserie1=log(serie1)

(modA=arima(lnserie1,order=pdq,seasonal=list(order=PDQ,period=12))) # whole time series
(modB=arima(lnserie2,order=pdq,seasonal=list(order=PDQ,period=12))) # model without last observations
```
model D is based on the training data set.
model C is based on the whole data set.

Model 1 is stable.


```{r}
# # Based on Model 1
# ultim=c(2018,12) # ending one year before the end of the time series: 12 observations

# Model 1 Parameters
# pdq=c(0,1,2)
# PDQ=c(0,1,1)

# serie2=window(series,end=ultim)
# lnserie2=log(serie2)
# serie1=window(series,end=ultim+c(1,0)) # adds one year
# lnserie1=log(serie1)

# (modC=arima(lnserie1,order=pdq,seasonal=list(order=PDQ,period=12))) # whole time series
# (modD=arima(lnserie2,order=pdq,seasonal=list(order=PDQ,period=12))) # model without last observations
```


## Prediction: 
```{r}
pred=predict(modB,n.ahead=12)
pr<-ts(c(tail(lnserie2,1),pred$pred),start=ultim,freq=12)
se<-ts(c(0,pred$se),start=ultim,freq=12)

#Intervals
tl<-ts(exp(pr-1.96*se),start=ultim,freq=12)
tu<-ts(exp(pr+1.96*se),start=ultim,freq=12)
pr<-ts(exp(pr),start=ultim,freq=12)


ts.plot(series,tl,tu,pr,lty=c(1,2,2,1),col=c(1,4,4,2),xlim=ultim[1]+c(-2,+2),type="o",main=paste("Model ARIMA(",paste(pdq,collapse=","),")(",paste(PDQ,collapse=","),")12",sep=""))
abline(v=(ultim[1]-2):(ultim[1]+2),lty=3,col=4)
```


```{r}
obs=window(series,start=ultim+c(0,1))
pr=window(pr,start=ultim+c(0,1))
ts(data.frame(LowLim=tl[-1],Predic=pr,UpperLim=tu[-1],Observ=obs,Error=obs-pr,PercentError=(obs-pr)/obs),start=ultim+c(0,1),freq=12)
```

```{r}
mod.RMSE1=sqrt(sum((obs-pr)^2)/12)
mod.MAE1=sum(abs(obs-pr))/12
mod.RMSPE1=sqrt(sum(((obs-pr)/obs)^2)/12)
mod.MAPE1=sum(abs(obs-pr)/obs)/12

data.frame("RMSE"=mod.RMSE1,"MAE"=mod.MAE1,"RMSPE"=mod.RMSPE1,"MAPE"=mod.MAPE1)
```


```{r}
mCI1=mean(tu-tl)

cat("\nMean Length CI: ",mCI1)
```
```{r}
series
```


